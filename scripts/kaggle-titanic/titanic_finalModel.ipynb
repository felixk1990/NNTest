{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ede3f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import os\n",
    "import os.path as op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ec9575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/kaggle-titanic/train_label.csv\n",
      "../../data/kaggle-titanic/test_RescaleClean.csv\n",
      "../../data/kaggle-titanic/train_RescaleClean.csv\n",
      "../../data/kaggle-titanic/test.csv\n",
      "../../data/kaggle-titanic/train.csv\n",
      "../../data/kaggle-titanic/significantFeatures.txt\n",
      "   Pclass  Sex  SibSp  Parch  Fare_group  Embarked  Age_group  Title\n",
      "0     1.0  0.0  0.125    0.0         0.0       0.0        0.2    0.0\n",
      "1     0.0  1.0  0.125    0.0         0.0       0.5        0.4    0.0\n",
      "2     1.0  1.0  0.000    0.0         0.0       0.0        0.2    1.0\n",
      "3     0.0  1.0  0.125    0.0         0.0       0.0        0.4    0.0\n",
      "4     1.0  0.0  0.000    0.0         0.0       0.0        0.4    0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      891 non-null    float64\n",
      " 1   Sex         891 non-null    float64\n",
      " 2   SibSp       891 non-null    float64\n",
      " 3   Parch       891 non-null    float64\n",
      " 4   Fare_group  891 non-null    float64\n",
      " 5   Embarked    891 non-null    float64\n",
      " 6   Age_group   891 non-null    float64\n",
      " 7   Title       891 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 62.6 KB\n",
      "None\n",
      "   Survived\n",
      "0         0\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 891 entries, 0 to 890\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   Survived  891 non-null    int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 13.9 KB\n",
      "None\n",
      "   Pclass  Sex  SibSp     Parch  Fare_group  Embarked  Age_group  Title\n",
      "0     1.0  0.0  0.000  0.000000         0.0       1.0        0.4    0.0\n",
      "1     1.0  1.0  0.125  0.000000         0.0       0.0        0.6    0.0\n",
      "2     0.5  0.0  0.000  0.000000         0.0       1.0        0.8    0.0\n",
      "3     1.0  0.0  0.000  0.000000         0.0       0.0        0.4    0.0\n",
      "4     1.0  1.0  0.125  0.111111         0.0       0.0        0.2    0.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Pclass      418 non-null    float64\n",
      " 1   Sex         418 non-null    float64\n",
      " 2   SibSp       418 non-null    float64\n",
      " 3   Parch       418 non-null    float64\n",
      " 4   Fare_group  418 non-null    float64\n",
      " 5   Embarked    418 non-null    float64\n",
      " 6   Age_group   418 non-null    float64\n",
      " 7   Title       418 non-null    float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 29.4 KB\n",
      "None\n",
      "['Pclass', 'Sex', 'SibSp', 'Fare_group', 'Title']\n"
     ]
    }
   ],
   "source": [
    "path = '../../data/kaggle-titanic'\n",
    "for dirname, _, filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "        \n",
    "setNames = ['train_RescaleClean.csv','train_label.csv','test_RescaleClean.csv']\n",
    "data = []\n",
    "for sn in setNames:\n",
    "    data.append( pd.read_csv(op.join(path,sn), index_col=0))\n",
    "    print(data[-1].head())\n",
    "    print(data[-1].info())\n",
    "        \n",
    "test_data = pd.read_csv(op.join(path, \"test.csv\"))\n",
    "    \n",
    "with open(op.join(path,\"significantFeatures.txt\"), \"r\") as file:\n",
    "    features = [f.split('\\n')[0] for f in file.readlines()]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a25c4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('tree',\n",
       "                                RandomForestClassifier(max_depth=5,\n",
       "                                                       random_state=1)),\n",
       "                               ('mlp',\n",
       "                                MLPClassifier(learning_rate='adaptive',\n",
       "                                              max_iter=5000, random_state=1,\n",
       "                                              tol=1e-09)),\n",
       "                               ('svm', SVC()), ('sgd', SGDClassifier()),\n",
       "                               ('NB', GaussianNB())],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stagged models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "X, y, X_test = data[0][features], data[1]['Survived'],data[2][features]\n",
    "estimators = [('tree', RandomForestClassifier(n_estimators=100, max_depth=5, random_state=1)),\n",
    "              ('mlp', MLPClassifier(hidden_layer_sizes=(100,), random_state=1, max_iter = 5000, learning_rate='adaptive', tol=1e-9)),\n",
    "              ('svm', svm.SVC()),('sgd', SGDClassifier()), ('NB', GaussianNB())]\n",
    "\n",
    "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a4f7c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your submission was successfully saved!\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': y_pred})\n",
    "output.to_csv(op.join(path, 'submission.csv'), index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e6b59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
